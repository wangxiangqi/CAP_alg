{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         y      x      z       a    u\n",
      "2378   0.0  126.0  109.0   326.0  1.0\n",
      "376    4.0  124.0  102.0   588.0  2.0\n",
      "1948   6.0  128.0  105.0  1537.0  2.0\n",
      "3893   3.0  118.0  116.0   494.0  3.0\n",
      "568    8.0  117.0  116.0  1096.0  3.0\n",
      "...    ...    ...    ...     ...  ...\n",
      "3444   4.0  118.0  110.0   739.0  3.0\n",
      "466   15.0  111.0   97.0  1686.0  3.0\n",
      "3092   2.0  125.0  108.0   375.0  1.0\n",
      "3772  14.0  114.0   78.0  1940.0  3.0\n",
      "860   12.0  128.0   79.0  1973.0  3.0\n",
      "\n",
      "[3924 rows x 5 columns]\n",
      "         y      x      z       a    u\n",
      "179    4.0  126.0  100.0   505.0  1.0\n",
      "3166   2.0  119.0  112.0   637.0  3.0\n",
      "2740  10.0  119.0   96.0  1092.0  3.0\n",
      "2191   6.0  121.0  109.0   628.0  2.0\n",
      "1578   6.0  120.0  109.0   540.0  1.0\n",
      "...    ...    ...    ...     ...  ...\n",
      "596    4.0  108.0  123.0   634.0  4.0\n",
      "911    0.0  124.0  108.0   305.0  1.0\n",
      "4034  11.0  116.0  108.0  1038.0  3.0\n",
      "1626   8.0  113.0   89.0  1099.0  2.0\n",
      "2099  14.0  121.0  108.0  2310.0  2.0\n",
      "\n",
      "[437 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data=pd.io.stata.read_stata(\"E:/summer_intern/CAP_alg/data/fertil2.dta\")\n",
    "data = data.fillna(data.mode().iloc[0])\n",
    "train_data, test_data = train_test_split(data, test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "# Save the train_data and test_data to CSV files\n",
    "train_data.to_csv(\"E:/summer_intern/CAP_alg/data/train_data.csv\")\n",
    "test_data.to_csv(\"E:/summer_intern/CAP_alg/data/test_data.csv\")\n",
    "train_data['y'] = train_data['ceb']+train_data['children']\n",
    "test_data['y'] = test_data['ceb']+test_data['children']\n",
    "train_data=train_data.drop(columns=['ceb', 'children'])\n",
    "test_data=test_data.drop(columns=['ceb', 'children'])\n",
    "# Create y column\n",
    "import numpy as np\n",
    "# Merge columns 1 to 8 and 10 into a single column 'x'\n",
    "#import pandas as pd\n",
    "train_data['x'] = train_data.iloc[:, :9].sum(axis=1)\n",
    "test_data['x'] = test_data.iloc[:, :9].sum(axis=1)\n",
    "# Drop the original columns 1 to 8 and 10\n",
    "train_data = train_data.drop(train_data.iloc[:, :9], axis=1)\n",
    "test_data = test_data.drop(test_data.iloc[:, :9], axis=1)\n",
    "\n",
    "train_data['z'] = train_data.iloc[:, :5].sum(axis=1)\n",
    "test_data['z'] = test_data.iloc[:, :5].sum(axis=1)\n",
    "# Drop the original columns 1 to 8 and 10\n",
    "train_data = train_data.drop(train_data.iloc[:, :5], axis=1)\n",
    "test_data = test_data.drop(test_data.iloc[:, :5], axis=1)\n",
    "\n",
    "train_data['a'] = train_data.iloc[:, :5].sum(axis=1)\n",
    "test_data['a'] = test_data.iloc[:, :5].sum(axis=1)\n",
    "# Drop the original columns 1 to 8 and 10\n",
    "train_data = train_data.drop(train_data.iloc[:, :5], axis=1)\n",
    "test_data = test_data.drop(test_data.iloc[:, :5], axis=1)\n",
    "\n",
    "train_data['u'] = train_data.iloc[:, :6].sum(axis=1)\n",
    "test_data['u'] = test_data.iloc[:, :6].sum(axis=1)\n",
    "# Drop the original columns 1 to 8 and 10\n",
    "train_data = train_data.drop(train_data.iloc[:, :6], axis=1)\n",
    "test_data = test_data.drop(test_data.iloc[:, :6], axis=1)\n",
    "\n",
    "print(train_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'E:/summer_intern/CAP_alg/src')\n",
    "import CAP_algorithm\n",
    "from CAP_algorithm import CAP_policy_learning_IV\n",
    "#print(train_data)\n",
    "#print(train_data['x'].shape[0], train_data['a'].shape[0])\n",
    "from contextualbandits.online import BootstrappedUCB, BootstrappedTS, LinUCB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "#print(dataset)\n",
    "\n",
    "#print(context_dataset.shape[0])\n",
    "#policy.fit(X=context_dataset,a=np.array(train_data['a']),r=np.array(train_data['y']))\n",
    "policy=CAP_policy_learning_IV(train_data)\n",
    "#policy都做的builtin，没有做接口\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use CAP method based on CCB-IV model, we exploit the FERTIL2 dataset\n",
    "\n",
    "About FERTIL2 dataset:\n",
    "The goal of this dataset is to study the impact of women's education for more than seven years (or exactly seven) years on the number of children in a household. It contains several observational confounding factors, such as age, television ownership, urban residence, etc. The instrumental variable is a binary indicator that indicates whether a woman was born in the first half of the year. This dataset is often used for the study of tool variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test with baselines and regret analysis:\n",
    "from contextualbandits.online import LinTS\n",
    "\n",
    "policy_ori=LinTS(10)\n",
    "policy_ori.fit(train_data['x'], train_data['a'],train_data['y'])\n",
    "from UC_DTR import uc_dtr_simulation\n",
    "## Draw the regret diagram and analyze it\n",
    "batch_size=10\n",
    "from contextualbandits.evaluation import evaluateFullyLabeled\n",
    "ori_list=[]\n",
    "for i in range(0, len(test_data), batch_size):\n",
    "    batch = test_data[i:i+batch_size]\n",
    "    ori_list.append(evaluateFullyLabeled(policy_ori,batch['x'],batch['y']))\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(ori_list)\n",
    "plt.show()\n",
    "\n",
    "## Try to plot CAP_alg regret graph:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we implement CCB_PV simulation based on the coding\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
